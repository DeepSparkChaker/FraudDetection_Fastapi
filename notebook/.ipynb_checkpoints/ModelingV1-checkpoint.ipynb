{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load the librarys\n",
    "import pandas as pd #To work with dataset\n",
    "import numpy as np #Math library\n",
    "import matplotlib.gridspec as gridspec\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly import tools\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "import seaborn as sns #Graph library that use matplot in background\n",
    "import matplotlib.pyplot as plt #to plot some parameters in seaborn\n",
    "# Preparation  \n",
    "#import category_encoders as ce\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import PowerTransformer, StandardScaler,Normalizer,RobustScaler,MaxAbsScaler,MinMaxScaler,QuantileTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "# Import StandardScaler from scikit-learn\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer,IterativeImputer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.compose import make_column_transformer,ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline,FeatureUnion\n",
    "from sklearn.manifold import TSNE\n",
    "# Import train_test_split()\n",
    "# Metrics\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.metrics import make_scorer,precision_score,recall_score,f1_score\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.metrics import roc_curve,confusion_matrix,classification_report\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from datetime import datetime, date\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC,LinearRegression\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "#import smogn\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import GradientBoostingRegressor,RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier,HistGradientBoostingRegressor\n",
    "# For training random forest model\n",
    "import lightgbm as lgb\n",
    "from scipy import sparse\n",
    "from sklearn.neighbors import KNeighborsRegressor \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans \n",
    "# Model selection\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression,f_classif,chi2\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import mutual_info_classif,VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from lightgbm import LGBMClassifier,LGBMRegressor\n",
    "import lightgbm as lgbm\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from xgboost import XGBClassifier,XGBRegressor\n",
    "from sklearn import set_config\n",
    "from itertools import combinations\n",
    "\n",
    "#import smong \n",
    "\n",
    "import os \n",
    "import warnings\n",
    "# import optuna \n",
    "from joblib import Parallel, delayed\n",
    "import joblib \n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from sklearn import set_config\n",
    "from abc import ABC, abstractmethod\n",
    "set_config(display='diagram')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Model config in json format\"\"\"\n",
    "cfg= {\n",
    "    \"data\": {\n",
    "        \"path\": \"C:/Users/rzouga/Desktop/ALLINHERE/ALLINHERE/FraudDetection/transactions_train.csv\"\n",
    "    },\n",
    "    #\"data_test\": {\n",
    "     #   \"path\": \"../input/ventilator-pressure-prediction/test.csv\"\n",
    "    #},\n",
    "    #\"data_submission\": {\n",
    "     #   \"path\": \"../input/ventilator-pressure-prediction/test.csv\"\n",
    "    #},\n",
    "    \"train\": {\n",
    "        'fit_params' :{'early_stopping_rounds':100,'verbose':55000},\n",
    "         'n_fold':5,\n",
    "         'seeds': [2021],\n",
    "         'target_col' : \"pressure\",\n",
    "         'debug' : False\n",
    "       \n",
    "    },\n",
    "    \"model\":{\n",
    "    \"learning_rate\": 0.008,\n",
    "    'metric':'auc',\n",
    "    'objective':'binary',\n",
    "    'device': 'gpu',\n",
    "    'n_estimators': 3205,\n",
    "    'num_leaves': 184,\n",
    "    'min_child_samples': 63,\n",
    "    'feature_fraction': 0.6864594334728974,\n",
    "    'bagging_fraction': 0.9497327922401265,\n",
    "    'bagging_freq': 1,\n",
    "    'reg_alpha': 19,\n",
    "    'reg_lambda': 19,\n",
    "    'gpu_platform_id': 0\n",
    "}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Logger:\n",
    "    \"\"\"save log\"\"\"\n",
    "    def __init__(self, path):\n",
    "        self.general_logger = logging.getLogger(path)\n",
    "        stream_handler = logging.StreamHandler()\n",
    "        file_general_handler = logging.FileHandler(os.path.join(path, 'Experiment.log'))\n",
    "        if len(self.general_logger.handlers) == 0:\n",
    "            self.general_logger.addHandler(stream_handler)\n",
    "            self.general_logger.addHandler(file_general_handler)\n",
    "            self.general_logger.setLevel(logging.INFO)\n",
    "\n",
    "    def info(self, message):\n",
    "        # display time\n",
    "        self.general_logger.info('[{}] - {}'.format(self.now_string(), message))\n",
    "\n",
    "    @staticmethod\n",
    "    def now_string():\n",
    "        return str(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    \n",
    "    \n",
    "class Util:\n",
    "    \"\"\"save & load\"\"\"\n",
    "    @classmethod\n",
    "    def dump(cls, value, path):\n",
    "        joblib.dump(value, path, compress=True)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path):\n",
    "        return joblib.load(path)\n",
    "        \n",
    "class HorizontalDisplay:\n",
    "    \"\"\"display dataframe\"\"\"\n",
    "    def __init__(self, *args):\n",
    "        self.args = args\n",
    "\n",
    "    def _repr_html_(self):\n",
    "        template = '<div style=\"float: left; padding: 10px;\">{0}</div>'\n",
    "        return \"\\n\".join(template.format(arg._repr_html_())\n",
    "                         for arg in self.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "INPUT = \"../input/ventilator-pressure-prediction\"\n",
    "EXP = \"./\"\n",
    "EXP_MODEL = os.path.join(EXP, \"model\")\n",
    "EXP_FIG = os.path.join(EXP, \"fig\")\n",
    "EXP_PREDS = os.path.join(EXP, \"preds\")\n",
    "\n",
    "# make dirs\n",
    "for d in [EXP_MODEL, EXP_FIG, EXP_PREDS]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# utils\n",
    "logger = Logger(EXP)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Config class\"\"\"\n",
    "import json\n",
    "from types import SimpleNamespace\n",
    "class Config:\n",
    "    name_v1 = \"lgb baseline\"\n",
    "    \"\"\"Config class which contains data, train and model hyperparameters\"\"\"\n",
    "    def __init__(self, data, train, model):\n",
    "        self.data = data\n",
    "        self.train = train\n",
    "        self.model = model\n",
    "    @classmethod\n",
    "    def from_json(cls, cfg):\n",
    "        \"\"\"Creates config from json\"\"\"\n",
    "        params = json.loads(json.dumps(cfg), object_hook=lambda d: SimpleNamespace(**d))\n",
    "        return cls(params.data, params.train, params.model)\n",
    "\n",
    "class HelperObject(object):\n",
    "    \"\"\"Helper class to convert json into Python object\"\"\"\n",
    "    def __init__(self, dict_):\n",
    "        self.__dict__.update(dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Data Loader\"\"\"\n",
    "class DataLoader:\n",
    "    \"\"\"Data Loader class\"\"\"\n",
    "    @staticmethod\n",
    "    def load_data(data_config):\n",
    "        \"\"\"Loads dataset from path\"\"\"\n",
    "        return pd.read_csv(data_config.path)\n",
    "    \n",
    "%time\n",
    "train=DataLoader.load_data(Config.from_json(cfg).data)\n",
    "train.head()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class FeatureEngineerTS(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #self.group_key = group_key\n",
    "    def fit(self,X, y=None):\n",
    "        return self\n",
    "    def aggregation(self ,input_df, group_key, group_values, agg_methods):\n",
    "        \"\"\"ref:https://github.com/pfnet-research/xfeat/blob/master/xfeat/helper.py\"\"\"\n",
    "        # https://www.kaggle.com/mst8823/google-brain-lightgbm-baseline\n",
    "        new_df = []\n",
    "        for agg_method in agg_methods:\n",
    "            for col in group_values:\n",
    "                if callable(agg_method):\n",
    "                    agg_method_name = agg_method.__name__\n",
    "                else:\n",
    "                    agg_method_name = agg_method\n",
    "                new_col = f\"agg_{agg_method_name}_{col}_grpby_{group_key}\"\n",
    "                df_agg = (input_df[[col] + [group_key]].groupby(group_key)[[col]].agg(agg_method))\n",
    "                df_agg.columns = [new_col]\n",
    "                new_df.append(df_agg)\n",
    "\n",
    "        _df = pd.concat(new_df, axis=1).reset_index()\n",
    "        output_df = pd.merge(input_df[[group_key]], _df, on=group_key, how=\"left\")\n",
    "        return output_df.drop(group_key, axis=1)\n",
    "    def transform(self, X, y=None):\n",
    "        # Calculate some metrics across rows\n",
    "        X['cross']= X['u_in'] * X['u_out']\n",
    "        X['cross2']= X['time_step'] * X['u_out']\n",
    "        X['area'] = X['time_step'] * X['u_in']\n",
    "        X['area'] = X.groupby('breath_id')['area'].cumsum()\n",
    "        X['time_step_cumsum'] = X.groupby(['breath_id'])['time_step'].cumsum()\n",
    "        X['u_in_cumsum'] = (X['u_in']).groupby(X['breath_id']).cumsum()\n",
    "        print(\"Step-1...Completed\")\n",
    "        X = X.fillna(0)\n",
    "        X['R'] = X['R'].astype(str)\n",
    "        X['C'] = X['C'].astype(str)\n",
    "        X['R__C'] =X[\"R\"].astype(str) + '__' + X[\"C\"].astype(str)\n",
    "       # df = pd.get_dummies(df)\n",
    "        print(\"Step-2...Completed\")\n",
    "        count_in_sequences = 80\n",
    "        X['cum_count']=X.groupby('breath_id').cumcount()+1\n",
    "        X['month_sin'] = np.sin(2*np.pi*X['cum_count']/count_in_sequences)\n",
    "        X['month_cos'] = np.cos(2*np.pi*X['cum_count']/count_in_sequences)\n",
    "        X.drop(['id', 'breath_id'], axis=1, inplace=True)\n",
    "        if 'pressure' in X.columns:\n",
    "            X.drop('pressure', axis=1, inplace=True)\n",
    "        if 'cum_count' in X.columns:\n",
    "            X.drop('cum_count', axis=1, inplace=True)\n",
    "        X[X.select_dtypes(['float64']).columns] = X[X.select_dtypes(['float64']).columns].apply(pd.to_numeric)\n",
    "        X[X.select_dtypes(['object']).columns] = X.select_dtypes(['object']).apply(lambda x: x.astype('category'))\n",
    "        X[X.select_dtypes(['float64','float16']).columns] = X[X.select_dtypes(['float64','float16']).columns].apply(pd.to_numeric)\n",
    "        X[X.select_dtypes(['object','int8']).columns] = X.select_dtypes(['object','int8']).apply(lambda x: x.astype('category'))\n",
    "        return X\n",
    "#########################################################    \n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Select only specified columns.\"\"\"\n",
    "    def __init__(self, positions):\n",
    "        self.positions = positions\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X,y=None):\n",
    "        #return np.array(X)[:, self.positions]\n",
    "        return X.loc[:, self.positions]\n",
    "    # Positional Selector \n",
    "class PositionalSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, positions):\n",
    "        self.positions = positions\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array(X)[:, self.positions]\n",
    "\n",
    "# Author : https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        name =df[col].dtype.name \n",
    "        \n",
    "        if col_type != object and col_type.name != 'category':\n",
    "        #if name != \"category\":    \n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>type</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldbalanceOrig</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>9839.64</td>\n",
       "      <td>C1231006815</td>\n",
       "      <td>170136.0</td>\n",
       "      <td>160296.36</td>\n",
       "      <td>M1979787155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>1864.28</td>\n",
       "      <td>C1666544295</td>\n",
       "      <td>21249.0</td>\n",
       "      <td>19384.72</td>\n",
       "      <td>M2044282225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C1305486145</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C553264065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C840083671</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C38997010</td>\n",
       "      <td>21182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>11668.14</td>\n",
       "      <td>C2048537720</td>\n",
       "      <td>41554.0</td>\n",
       "      <td>29885.86</td>\n",
       "      <td>M1230701703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step      type    amount     nameOrig  oldbalanceOrig  newbalanceOrig  \\\n",
       "0     1   PAYMENT   9839.64  C1231006815        170136.0       160296.36   \n",
       "1     1   PAYMENT   1864.28  C1666544295         21249.0        19384.72   \n",
       "2     1  TRANSFER    181.00  C1305486145           181.0            0.00   \n",
       "3     1  CASH_OUT    181.00   C840083671           181.0            0.00   \n",
       "4     1   PAYMENT  11668.14  C2048537720         41554.0        29885.86   \n",
       "\n",
       "      nameDest  oldbalanceDest  newbalanceDest  isFraud  \n",
       "0  M1979787155             0.0             0.0        0  \n",
       "1  M2044282225             0.0             0.0        0  \n",
       "2   C553264065             0.0             0.0        1  \n",
       "3    C38997010         21182.0             0.0        1  \n",
       "4  M1230701703             0.0             0.0        0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def clean_data(df, output_file='cleaned_data.csv'):\n",
    "\n",
    "    # Removes columns with missing values issues\n",
    "    cols_to_be_removed = ['Id', 'PoolQC', 'MiscFeature', 'Alley', 'Fence', 'LotFrontage',\n",
    "    'GarageYrBlt', 'MasVnrArea']\n",
    "    df.drop(columns=cols_to_be_removed, inplace=True)\n",
    "\n",
    "    # Transforms ordinal columns to numeric\n",
    "    ordinal_cols = ['FireplaceQu', 'ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', \n",
    "    'HeatingQC', 'KitchenQual', 'GarageQual', 'GarageCond']\n",
    "    for col in ordinal_cols:\n",
    "        df[col].fillna(0, inplace=True)\n",
    "        df[col].replace({'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}, inplace=True)\n",
    "\n",
    "    # Fills NA where incorrectly pandas placed NaN\n",
    "    for c in ['GarageType', 'GarageFinish', 'BsmtFinType2', 'BsmtExposure', 'BsmtFinType1']:\n",
    "        df[c].fillna('NA', inplace=True)\n",
    "\n",
    "    # Fills None where incorrectly pandas placed NaN\n",
    "    df['MasVnrType'].fillna('None', inplace=True)\n",
    "\n",
    "    # Imputes with most frequent value\n",
    "    df['Electrical'].fillna('SBrkr', inplace=True)\n",
    "\n",
    "    # Saves a copy\n",
    "    df.to_csv(output_file)\n",
    "\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv('raw_data.csv')\n",
    "    print(f'Original Data: {df.shape}')\n",
    "    cleaned_df = clean_data(df)\n",
    "\n",
    "    columns_with_miss = cleaned_df.isna().sum()\n",
    "    columns_with_miss = columns_with_miss[columns_with_miss!=0]\n",
    "    print(f'Columns with missing values: {len(columns_with_miss)}')\n",
    "    print(columns_with_miss.sort_values(ascending=False))\n",
    "\n",
    "    print(f'After Cleaning: {cleaned_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# select the float columns\n",
    "num_columns = train.drop(['isFraud'], axis=1).select_dtypes(include=['int64','float64']).columns\n",
    "#num_columns= [train.columns.get_loc(col) for col in num_columns]\n",
    "#num_columns=[0, 2, 4, 5, 7, 8]\n",
    "#cat_columns=[1, 3, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# select non-numeric columns\n",
    "cat_columns = train.drop(['isFraud'], axis=1).select_dtypes(exclude=['int64','float64']).columns\n",
    "# cat_columns= [train.columns.get_loc(col) for col in cat_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['type', 'nameOrig', 'nameDest'], dtype='object')\n",
      "Index(['step', 'amount', 'oldbalanceOrig', 'newbalanceOrig', 'oldbalanceDest',\n",
      "       'newbalanceDest'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# select non-numeric columns\n",
    "#cat_columns = train.select_dtypes(include=['object','category','int64']).columns\n",
    "# select the float columns\n",
    "#num_columns = train.select_dtypes(exclude=['object','category','int64']).columns\n",
    "print(cat_columns)\n",
    "print(num_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-8b4decc20daa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Clasic way :\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m params={\"learning_rate\": Config.from_json(cfg).model.learning_rate,\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[1;31m#'device': Config.from_json(cfg).model.device,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;34m'metric'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mConfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;34m'objective'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mConfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Config' is not defined"
     ]
    }
   ],
   "source": [
    "# Clasic way : \n",
    "params={\"learning_rate\": Config.from_json(cfg).model.learning_rate,\n",
    "        #'device': Config.from_json(cfg).model.device,\n",
    "        'metric':Config.from_json(cfg).model.metric,\n",
    "        'objective':Config.from_json(cfg).model.objective,\n",
    "        'n_estimators':  Config.from_json(cfg).model.n_estimators,\n",
    "        'num_leaves': Config.from_json(cfg).model.num_leaves,\n",
    "        'min_child_samples':  Config.from_json(cfg).model.min_child_samples,\n",
    "        'feature_fraction': Config.from_json(cfg).model.feature_fraction,\n",
    "        'bagging_fraction': Config.from_json(cfg).model.bagging_fraction,\n",
    "        'bagging_freq':  Config.from_json(cfg).model.bagging_freq,\n",
    "        'reg_alpha':  Config.from_json(cfg).model.reg_alpha,\n",
    "        'reg_lambda':  Config.from_json(cfg).model.reg_lambda,\n",
    "       # 'gpu_platform_id':  Config.from_json(cfg).model.gpu_platform_id\n",
    "            }\n",
    "model_lgbm  = LGBMRegressor(**params)\n",
    "class ColumnsSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, positions):\n",
    "        self.positions = positions\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        #return np.array(X)[:, self.positions]\n",
    "        return X.loc[:, self.positions] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-c23b72bb-7373-44e2-a488-ce83ed1aea31 {color: black;background-color: white;}#sk-c23b72bb-7373-44e2-a488-ce83ed1aea31 pre{padding: 0;}#sk-c23b72bb-7373-44e2-a488-ce83ed1aea31 div.sk-toggleable {background-color: white;}#sk-c23b72bb-7373-44e2-a488-ce83ed1aea31 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-c23b72bb-7373-44e2-a488-ce83ed1aea31 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-c23b72bb-7373-44e2-a488-ce83ed1aea31 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-c23b72bb-7373-44e2-a488-ce83ed1aea31 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-c23b72bb-7373-44e2-a488-ce83ed1aea31 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-c23b72bb-7373-44e2-a488-ce83ed1aea31 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-c23b72bb-7373-44e2-a488-ce83ed1aea31 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-c23b72bb-7373-44e2-a488-ce83ed1aea31 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-c23b72bb-7373-44e2-a488-ce83ed1aea31 div.sk-estimator:hover {background-color: #d4ebff;}#sk-c23b72bb-7373-44e2-a488-ce83ed1aea31 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-c23b72bb-7373-44e2-a488-ce83ed1aea31 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-c23b72bb-7373-44e2-a488-ce83ed1aea31 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-c23b72bb-7373-44e2-a488-ce83ed1aea31 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-c23b72bb-7373-44e2-a488-ce83ed1aea31 div.sk-item {z-index: 1;}#sk-c23b72bb-7373-44e2-a488-ce83ed1aea31 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-c23b72bb-7373-44e2-a488-ce83ed1aea31 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-c23b72bb-7373-44e2-a488-ce83ed1aea31 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-c23b72bb-7373-44e2-a488-ce83ed1aea31 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-c23b72bb-7373-44e2-a488-ce83ed1aea31 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-c23b72bb-7373-44e2-a488-ce83ed1aea31 div.sk-parallel-item:only-child::after {width: 0;}#sk-c23b72bb-7373-44e2-a488-ce83ed1aea31 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-c23b72bb-7373-44e2-a488-ce83ed1aea31 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-c23b72bb-7373-44e2-a488-ce83ed1aea31 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-c23b72bb-7373-44e2-a488-ce83ed1aea31 div.sk-container {display: inline-block;position: relative;}</style><div id=\"sk-c23b72bb-7373-44e2-a488-ce83ed1aea31\" class\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"dc75437e-ee62-408a-a5b4-370c891dc7ce\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"dc75437e-ee62-408a-a5b4-370c891dc7ce\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('pre',\n",
       "                 ColumnTransformer(transformers=[('cat_columns',\n",
       "                                                  Pipeline(steps=[('Encoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  Index(['type', 'nameOrig', 'nameDest'], dtype='object')),\n",
       "                                                 ('num_columns',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('scaler',\n",
       "                                                                   QuantileTransformer())]),\n",
       "                                                  Index(['step', 'amount', 'oldbalanceOrig', 'newbalanceOrig', 'oldbalanceDest',\n",
       "       'newbalanceDest'],\n",
       "      dtype='object'))])),\n",
       "                ('lgbm',\n",
       "                 LGBMRegressor(bagging_fraction=0.9497327922401265,\n",
       "                               bagging_freq=1,\n",
       "                               feature_fraction=0.6864594334728974,\n",
       "                               learning_rate=0.008, metric='auc',\n",
       "                               min_child_samples=63, n_estimators=3205,\n",
       "                               num_leaves=184, objective='binary', reg_alpha=19,\n",
       "                               reg_lambda=19))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"bc7f69a1-96f5-49fb-bd23-e679d60e0af8\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"bc7f69a1-96f5-49fb-bd23-e679d60e0af8\">pre: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[('cat_columns',\n",
       "                                 Pipeline(steps=[('Encoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                 Index(['type', 'nameOrig', 'nameDest'], dtype='object')),\n",
       "                                ('num_columns',\n",
       "                                 Pipeline(steps=[('imputer',\n",
       "                                                  SimpleImputer(strategy='median')),\n",
       "                                                 ('scaler',\n",
       "                                                  QuantileTransformer())]),\n",
       "                                 Index(['step', 'amount', 'oldbalanceOrig', 'newbalanceOrig', 'oldbalanceDest',\n",
       "       'newbalanceDest'],\n",
       "      dtype='object'))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"260721ba-36a7-4e15-822b-b89d8f8ec7db\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"260721ba-36a7-4e15-822b-b89d8f8ec7db\">cat_columns</label><div class=\"sk-toggleable__content\"><pre>Index(['type', 'nameOrig', 'nameDest'], dtype='object')</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"40777c89-4f32-4bda-bee9-334eea949812\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"40777c89-4f32-4bda-bee9-334eea949812\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown='ignore')</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"8760e747-f09b-4825-a4f4-c45954c3ee10\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"8760e747-f09b-4825-a4f4-c45954c3ee10\">num_columns</label><div class=\"sk-toggleable__content\"><pre>Index(['step', 'amount', 'oldbalanceOrig', 'newbalanceOrig', 'oldbalanceDest',\n",
       "       'newbalanceDest'],\n",
       "      dtype='object')</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"8eea2529-f4b3-42b7-ab8b-ae90000d1d53\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"8eea2529-f4b3-42b7-ab8b-ae90000d1d53\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy='median')</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"724af362-3764-4c94-9f7d-23bcf092a191\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"724af362-3764-4c94-9f7d-23bcf092a191\">QuantileTransformer</label><div class=\"sk-toggleable__content\"><pre>QuantileTransformer()</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"c39f0d3c-d177-42ed-a191-30ae02606c62\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"c39f0d3c-d177-42ed-a191-30ae02606c62\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(bagging_fraction=0.9497327922401265, bagging_freq=1,\n",
       "              feature_fraction=0.6864594334728974, learning_rate=0.008,\n",
       "              metric='auc', min_child_samples=63, n_estimators=3205,\n",
       "              num_leaves=184, objective='binary', reg_alpha=19, reg_lambda=19)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('pre',\n",
       "                 ColumnTransformer(transformers=[('cat_columns',\n",
       "                                                  Pipeline(steps=[('Encoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  Index(['type', 'nameOrig', 'nameDest'], dtype='object')),\n",
       "                                                 ('num_columns',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('scaler',\n",
       "                                                                   QuantileTransformer())]),\n",
       "                                                  Index(['step', 'amount', 'oldbalanceOrig', 'newbalanceOrig', 'oldbalanceDest',\n",
       "       'newbalanceDest'],\n",
       "      dtype='object'))])),\n",
       "                ('lgbm',\n",
       "                 LGBMRegressor(bagging_fraction=0.9497327922401265,\n",
       "                               bagging_freq=1,\n",
       "                               feature_fraction=0.6864594334728974,\n",
       "                               learning_rate=0.008, metric='auc',\n",
       "                               min_child_samples=63, n_estimators=3205,\n",
       "                               num_leaves=184, objective='binary', reg_alpha=19,\n",
       "                               reg_lambda=19))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cat_columns=['type']\n",
    "cat_pipe = Pipeline([#('selector', PositionalSelector(cat_columns)),\n",
    "                    # ('FeaturesEngineer', SparseInteractions(degree=2)),\n",
    "                    # ('imputer', SimpleImputer(strategy='constant', fill_value='missing',add_indicator=True)),\n",
    "                     # ('reducer', SelectKBest(score_func=mutual_info_classif, k=10)),\n",
    "                    # ('Encoder', ce.cat_boost.CatBoostEncoder())\n",
    "                     ('Encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "                     \n",
    "                    ])\n",
    "#Define value pipeline\n",
    "num_pipe = Pipeline([#('selector', PositionalSelector(num_columns)),\n",
    "                    # ('FeaturesEngineer', PolynomialFeatures(degree=2)),\n",
    "                     #('FeaturesEngineer',FeaturesEngineer()),\n",
    "                     # ('outlier',OutlierReplace()),\n",
    "                     ('imputer', SimpleImputer(strategy='median',add_indicator=False)),\n",
    "                     ('scaler', QuantileTransformer()),\n",
    "                     # PowerTransformer()\n",
    "                     # ('AddKmeans', MiniKmeansTransformer()),\n",
    "                     #('reducedim',  SelectPercentile(score_func=mutual_info_classif,\n",
    "                      #          percentile=98))\n",
    "                     #('dim_red', SelectKBest(mutual_info_classif, k=120))\n",
    "                     # ('FeaturesEngineer', PolynomialFeatures(degree=2)),\n",
    "                    ])\n",
    "#Featureunion fitting training data\n",
    "preprocessor = FeatureUnion(transformer_list=[('cat', cat_pipe),\n",
    "                                              ('num', num_pipe)])\n",
    "data_cleaning = ColumnTransformer([\n",
    "    ('cat_columns',  cat_pipe, cat_columns ),\n",
    "    ('num_columns', num_pipe , num_columns)\n",
    "])\n",
    "# preprocessor.fit(X_train)\n",
    "#############################\n",
    "# Complete Pipe \n",
    "def create_pipeline(model,preprocessor,FeaturesEngineer=None, ):\n",
    "    pipeline = Pipeline([ \n",
    "        #('FE', FeaturesEngineer),\n",
    "        ('pre', preprocessor),\n",
    "        # ('dim_red', SelectPercentile(mutual_info_classif, percentile=99)),\n",
    "        # ('interactions', SparseInteractions(degree=2)),\n",
    "        #('dim_red', PCA(0.80)),\n",
    "        ('lgbm', model)\n",
    "    ])\n",
    "    return pipeline\n",
    "\n",
    "paramsHGBC={'l2_regularization': 2.311620342927431,          \n",
    " 'early_stopping': 'False',\n",
    " 'learning_rate': 0.0775102184223046,\n",
    " 'max_iter': 1000,\n",
    " 'max_depth': 29,\n",
    " 'max_bins': 141,\n",
    " 'min_samples_leaf': 4707,\n",
    " 'max_leaf_nodes': 28}\n",
    "model_HGBR = HistGradientBoostingRegressor(**paramsHGBC)\n",
    "pipeline_model_lgbm = Pipeline([ \n",
    "        #('FE', FeaturesEngineer),\n",
    "        ('pre', data_cleaning),\n",
    "        # ('dim_red', SelectPercentile(mutual_info_classif, percentile=99)),\n",
    "        # ('interactions', SparseInteractions(degree=2)),\n",
    "        #('dim_red', PCA(0.80)),\n",
    "        ('lgbm', model_lgbm)\n",
    "    ])\n",
    "pipeline_model_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required Python libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Loading the iris dataset from Scikit-Learn\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# Converting the iris dataset into a Pandas DataFrame\n",
    "df_iris = pd.DataFrame(data = np.c_[iris['data'], iris['target']],\n",
    "\t\t\t\t\t\t\t\t\t\t\t columns = iris['feature_names'] + ['target'])\n",
    "\n",
    "# Separating the training dataset (X) from the predictor value (y)\n",
    "X = df_iris.drop(columns = ['target'])\n",
    "y = df_iris[['target']]\n",
    "\n",
    "# Instantiating a Logistic Regression (LR) model\n",
    "lr_model = LogisticRegression()\n",
    "\n",
    "# Fitting the dataset to the LR model\n",
    "lr_model.fit(X, y)\n",
    "\n",
    "# Saving the model to a serialized .pkl file\n",
    "pkl_filename = \"../model/iris_model.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "\tpickle.dump(lr_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle\n",
    "\n",
    "\n",
    "def create_train_test_data(dataset):\n",
    "    # load and split the data\n",
    "    data_train = dataset.sample(frac=0.8, random_state=30).reset_index(drop=True)\n",
    "    data_test = dataset.drop(data_train.index).reset_index(drop=True)\n",
    "\n",
    "    # save the data\n",
    "    data_train.to_csv('train.csv', index=False)\n",
    "    data_test.to_csv('test.csv', index=False)\n",
    "\n",
    "    print(f\"Train data for modeling: {data_train.shape}\")\n",
    "    print(f\"Test data for predictions: {data_test.shape}\")\n",
    "\n",
    "def train_model(x_train, y_train):\n",
    "\n",
    "    print(\"Training the model ...\")\n",
    "\n",
    "    model = Pipeline(steps=[\n",
    "        (\"label encoding\", OneHotEncoder(handle_unknown='ignore')),\n",
    "        (\"tree model\", LinearRegression())\n",
    "    ])\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    return model\n",
    "\n",
    "def accuracy(model, x_test, y_test):\n",
    "    print(\"Testing the model ...\")\n",
    "    predictions = model.predict(x_test)\n",
    "    tree_mse = mean_squared_error(y_test, predictions)\n",
    "    tree_rmse = np.sqrt(tree_mse)\n",
    "    return tree_rmse\n",
    "\n",
    "def export_model(model):\n",
    "    # Save the model\n",
    "    pkl_path = 'model.pkl'\n",
    "    with open(pkl_path, 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "        print(f\"Model saved at {pkl_path}\")\n",
    "\n",
    "def main():\n",
    "    # Load the whole data\n",
    "    data = pd.read_csv('cleaned_data.csv', keep_default_na=False, index_col=0)\n",
    "\n",
    "    # Split train/test\n",
    "    # Creates train.csv and test.csv\n",
    "    create_train_test_data(data)\n",
    "\n",
    "    # Loads the data for the model training\n",
    "    train = pd.read_csv('train.csv', keep_default_na=False)\n",
    "    x_train = train.drop(columns=['SalePrice'])\n",
    "    y_train = train['SalePrice']\n",
    "\n",
    "    # Loads the data for the model testing\n",
    "    test = pd.read_csv('test.csv', keep_default_na=False)\n",
    "    x_test = test.drop(columns=['SalePrice'])\n",
    "    y_test = test['SalePrice']\n",
    "\n",
    "    # Train and Test\n",
    "    model = train_model(x_train, y_train)\n",
    "    rmse_test = accuracy(model, x_test, y_test)\n",
    "\n",
    "    print(f\"Average Price Test: {y_test.mean()}\")\n",
    "    print(f\"RMSE: {rmse_test}\")\n",
    "\n",
    "    # Save the model\n",
    "    export_model(model)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model to a serialized .pkl file\n",
    "pkl_filename = \"../model/iris_model.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    " pickle.dump(lr_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create arrays for the features and the response variable\n",
    "y = train['isFraud'].to_numpy()\n",
    "X = train.drop(['isFraud'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X,y,stratify=y,  test_size = 0.98, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 39.2 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-4cb17918-b0ca-4385-a290-9b97e312a0d7 {color: black;background-color: white;}#sk-4cb17918-b0ca-4385-a290-9b97e312a0d7 pre{padding: 0;}#sk-4cb17918-b0ca-4385-a290-9b97e312a0d7 div.sk-toggleable {background-color: white;}#sk-4cb17918-b0ca-4385-a290-9b97e312a0d7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-4cb17918-b0ca-4385-a290-9b97e312a0d7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-4cb17918-b0ca-4385-a290-9b97e312a0d7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-4cb17918-b0ca-4385-a290-9b97e312a0d7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-4cb17918-b0ca-4385-a290-9b97e312a0d7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-4cb17918-b0ca-4385-a290-9b97e312a0d7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-4cb17918-b0ca-4385-a290-9b97e312a0d7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-4cb17918-b0ca-4385-a290-9b97e312a0d7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-4cb17918-b0ca-4385-a290-9b97e312a0d7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-4cb17918-b0ca-4385-a290-9b97e312a0d7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-4cb17918-b0ca-4385-a290-9b97e312a0d7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-4cb17918-b0ca-4385-a290-9b97e312a0d7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-4cb17918-b0ca-4385-a290-9b97e312a0d7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-4cb17918-b0ca-4385-a290-9b97e312a0d7 div.sk-item {z-index: 1;}#sk-4cb17918-b0ca-4385-a290-9b97e312a0d7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-4cb17918-b0ca-4385-a290-9b97e312a0d7 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-4cb17918-b0ca-4385-a290-9b97e312a0d7 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-4cb17918-b0ca-4385-a290-9b97e312a0d7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-4cb17918-b0ca-4385-a290-9b97e312a0d7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-4cb17918-b0ca-4385-a290-9b97e312a0d7 div.sk-parallel-item:only-child::after {width: 0;}#sk-4cb17918-b0ca-4385-a290-9b97e312a0d7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-4cb17918-b0ca-4385-a290-9b97e312a0d7 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-4cb17918-b0ca-4385-a290-9b97e312a0d7 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-4cb17918-b0ca-4385-a290-9b97e312a0d7 div.sk-container {display: inline-block;position: relative;}</style><div id=\"sk-4cb17918-b0ca-4385-a290-9b97e312a0d7\" class\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"85f2cf59-a40a-4f2c-8918-89e7fd704751\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"85f2cf59-a40a-4f2c-8918-89e7fd704751\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('pre',\n",
       "                 ColumnTransformer(transformers=[('cat_columns',\n",
       "                                                  Pipeline(steps=[('Encoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  Index(['type', 'nameOrig', 'nameDest'], dtype='object')),\n",
       "                                                 ('num_columns',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('scaler',\n",
       "                                                                   QuantileTransformer())]),\n",
       "                                                  Index(['step', 'amount', 'oldbalanceOrig', 'newbalanceOrig', 'oldbalanceDest',\n",
       "       'newbalanceDest'],\n",
       "      dtype='object'))])),\n",
       "                ('lgbm',\n",
       "                 LGBMRegressor(bagging_fraction=0.9497327922401265,\n",
       "                               bagging_freq=1,\n",
       "                               feature_fraction=0.6864594334728974,\n",
       "                               learning_rate=0.008, metric='auc',\n",
       "                               min_child_samples=63, n_estimators=3205,\n",
       "                               num_leaves=184, objective='binary', reg_alpha=19,\n",
       "                               reg_lambda=19))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"b90c59ab-410c-4ca0-bae8-8385029e2668\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"b90c59ab-410c-4ca0-bae8-8385029e2668\">pre: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[('cat_columns',\n",
       "                                 Pipeline(steps=[('Encoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                 Index(['type', 'nameOrig', 'nameDest'], dtype='object')),\n",
       "                                ('num_columns',\n",
       "                                 Pipeline(steps=[('imputer',\n",
       "                                                  SimpleImputer(strategy='median')),\n",
       "                                                 ('scaler',\n",
       "                                                  QuantileTransformer())]),\n",
       "                                 Index(['step', 'amount', 'oldbalanceOrig', 'newbalanceOrig', 'oldbalanceDest',\n",
       "       'newbalanceDest'],\n",
       "      dtype='object'))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"14499fa5-0b17-4dc4-a2d7-7422af04c31b\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"14499fa5-0b17-4dc4-a2d7-7422af04c31b\">cat_columns</label><div class=\"sk-toggleable__content\"><pre>Index(['type', 'nameOrig', 'nameDest'], dtype='object')</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"2182d459-1d0a-4572-a3c1-bc663e0f51d1\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"2182d459-1d0a-4572-a3c1-bc663e0f51d1\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown='ignore')</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"e4e1cd76-72e8-4893-9888-f65556b20087\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"e4e1cd76-72e8-4893-9888-f65556b20087\">num_columns</label><div class=\"sk-toggleable__content\"><pre>Index(['step', 'amount', 'oldbalanceOrig', 'newbalanceOrig', 'oldbalanceDest',\n",
       "       'newbalanceDest'],\n",
       "      dtype='object')</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"6093348d-f4c4-4c99-8886-23ef5f777932\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"6093348d-f4c4-4c99-8886-23ef5f777932\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy='median')</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"0f874d09-a8f7-4607-a45a-8aec18ddd479\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"0f874d09-a8f7-4607-a45a-8aec18ddd479\">QuantileTransformer</label><div class=\"sk-toggleable__content\"><pre>QuantileTransformer()</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"b8a48d14-35db-48b6-a81b-9eeab8978f49\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"b8a48d14-35db-48b6-a81b-9eeab8978f49\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(bagging_fraction=0.9497327922401265, bagging_freq=1,\n",
       "              feature_fraction=0.6864594334728974, learning_rate=0.008,\n",
       "              metric='auc', min_child_samples=63, n_estimators=3205,\n",
       "              num_leaves=184, objective='binary', reg_alpha=19, reg_lambda=19)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('pre',\n",
       "                 ColumnTransformer(transformers=[('cat_columns',\n",
       "                                                  Pipeline(steps=[('Encoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  Index(['type', 'nameOrig', 'nameDest'], dtype='object')),\n",
       "                                                 ('num_columns',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('scaler',\n",
       "                                                                   QuantileTransformer())]),\n",
       "                                                  Index(['step', 'amount', 'oldbalanceOrig', 'newbalanceOrig', 'oldbalanceDest',\n",
       "       'newbalanceDest'],\n",
       "      dtype='object'))])),\n",
       "                ('lgbm',\n",
       "                 LGBMRegressor(bagging_fraction=0.9497327922401265,\n",
       "                               bagging_freq=1,\n",
       "                               feature_fraction=0.6864594334728974,\n",
       "                               learning_rate=0.008, metric='auc',\n",
       "                               min_child_samples=63, n_estimators=3205,\n",
       "                               num_leaves=184, objective='binary', reg_alpha=19,\n",
       "                               reg_lambda=19))])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pipeline_model_lgbm.fit( X_train, y_train,\n",
    "                             #lgbm__eval_metric=\"auc\",\n",
    "                             #lgbm__eval_set = [(X_test, y_test)],\n",
    "                             #lgbm__verbose=1000,\n",
    "                             #lgbm__early_stopping_rounds = 50\n",
    "                            # lgbm__sample_weight=X_train_weight\n",
    "                           )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/rzouga/Desktop/ALLINHERE/ALLINHERE/FraudDetection/COMPLETREPO/FraudDetection_Fastapi/models/lgbm_localV1.joblib']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#joblib.dump(pipeline_model_lgbm,'pipeline_model_lgbm.sav')\n",
    "joblib.dump(pipeline_model_lgbm,\n",
    "            'C:/Users/rzouga/Desktop/ALLINHERE/ALLINHERE/FraudDetection/COMPLETREPO/FraudDetection_Fastapi/models/lgbm_localV1.joblib')\n",
    "#predictions_train = pipeline_model_lgbm.predict(train)\n",
    "#pd.DataFrame(predictions_train.to_csv(\"predictions_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class HousePriceModel():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = self.load_model()\n",
    "        self.preds = None\n",
    "\n",
    "    def load_model(self):\n",
    "        pkl_filename = 'model.pkl'\n",
    "\n",
    "        try:\n",
    "            with open(pkl_filename, 'rb') as file:\n",
    "                pickle_model = pickle.load(file)\n",
    "        except:\n",
    "            print(f'Error loading the model at {pkl_filename}')\n",
    "            return None\n",
    "\n",
    "        return pickle_model\n",
    "\n",
    "    def predict(self, data):\n",
    "\n",
    "        if not isinstance(data, pd.DataFrame):\n",
    "            data = pd.DataFrame(data, index=[0])\n",
    "\n",
    "        self.preds = self.model.predict(data)\n",
    "        return self.preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from datetime import datetime\n",
    "from predict import HousePriceModel\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.get(\"/\")\n",
    "def root():\n",
    "    return {\"status\": \"online\"}\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "def predict(inputs: dict):\n",
    "\n",
    "    model = HousePriceModel()\n",
    "\n",
    "    start = datetime.today()\n",
    "    pred = model.predict(inputs)[0]\n",
    "    dur = (datetime.today() - start).total_seconds()\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"step\":{\"0\":234},\"type\":{\"0\":\"CASH_OUT\"},\"amount\":{\"0\":305822.52},\"nameOrig\":{\"0\":\"C1376293938\"},\"oldbalanceOrig\":{\"0\":0.0},\"newbalanceOrig\":{\"0\":0.0},\"nameDest\":{\"0\":\"C182325611\"},\"oldbalanceDest\":{\"0\":1569390.8999999999},\"newbalanceDest\":{\"0\":1875213.4199999999}}'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load model data\n",
    "f = \"C:/Users/rzouga/Desktop/ALLINHERE/ALLINHERE/FraudDetection/COMPLETREPO/FraudDetection_Fastapi/models/lgbm_localV1.joblib\"\n",
    "model = joblib.load(f)\n",
    "item={}\n",
    "item={\"step\":234,\n",
    "       \"type\":\"CASH_OUT\",\n",
    "       \"amount\":305822.52,\n",
    "       \"nameOrig\":\"C1376293938\",\n",
    "       \"oldbalanceOrig\":0.0,\n",
    "       \"newbalanceOrig\":0.0,\n",
    "       \"nameDest\":\"C182325611\",\n",
    "       \"oldbalanceDest\":1569390.8999999999,\n",
    "       \"newbalanceDest\":1875213.4199999999}\n",
    "df = pd.json_normalize(item)\n",
    "df2 =pd.DataFrame([item])\n",
    "#data = test1.dict()\n",
    "#step=data['step']\n",
    "#type=data['type']\n",
    "#amount=data['amount']\n",
    "#nameOrig=data['nameOrig']\n",
    "#oldbalanceOrig=data['oldbalanceOrig']\n",
    "#newbalanceOrig=data['newbalanceOrig']\n",
    "#oldbalanceDest=data['oldbalanceDest']\n",
    "#newbalanceDest=data['newbalanceDest']\n",
    "# print(classifier.predict([[variance,skewness,curtosis,entropy]]))\n",
    "#prediction = classifier.predict([[variance,skewness,curtosis,entropy]])\n",
    "# Predicting Test Set\n",
    "test2={\"step\":item[\"step\"],\n",
    "       \"type\":item[\"type\"],\n",
    "       \"amount\":item[\"amount\"],\n",
    "       \"nameOrig\":item[\"nameOrig\"],\n",
    "       \"oldbalanceOrig\":item[\"oldbalanceOrig\"],\n",
    "       \"newbalanceOrig\":item[\"newbalanceOrig\"],\n",
    "       \"nameDest\":item[\"nameDest\"],\n",
    "       \"oldbalanceDest\":item[\"oldbalanceDest\"],\n",
    "       \"newbalanceDest\":item[\"newbalanceDest\"]}\n",
    "\n",
    "data_dict = pd.DataFrame(\n",
    "        {\n",
    "            'step': [item[\"step\"]],\n",
    "            'type': [item[\"type\"]],\n",
    "            'amount': [item[\"amount\"]],\n",
    "            'nameOrig': [item[\"nameOrig\"]],\n",
    "            'oldbalanceOrig': [item['oldbalanceOrig']],\n",
    "            'newbalanceOrig': [item[\"newbalanceOrig\"]],\n",
    "            'nameDest': [item[\"nameDest\"]],\n",
    "            'oldbalanceDest': [item[\"oldbalanceDest\"]],\n",
    "            'newbalanceDest': [item[\"newbalanceDest\"]]\n",
    "        }\n",
    "    )\n",
    "#prediction = model.predict(data_dict)\n",
    "#if (prediction[0] > 0.5):\n",
    " #   prediction = \"Fraud\"\n",
    "#else:\n",
    " #   prediction = \"Not Fraud\"\n",
    "data_dict.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'step': {'0': 234}, 'type': {'0': 'CASH_OUT'}, 'amount': {'0': 305822.52}, 'nameOrig': {'0': 'C1376293938'}, 'oldbalanceOrig': {'0': 0.0}, 'newbalanceOrig': {'0': 0.0}, 'nameDest': {'0': 'C182325611'}, 'oldbalanceDest': {'0': 1569390.9}, 'newbalanceDest': {'0': 1875213.42}}\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "app_json = json.loads(data_dict.to_json())\n",
    "print(app_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Not Fraud', 'Not Fraud']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load model data\n",
    "f = \"C:/Users/rzouga/Desktop/ALLINHERE/ALLINHERE/FraudDetection/COMPLETREPO/FraudDetection_Fastapi/models/lgbm_localV1.joblib\"\n",
    "model = joblib.load(f)\n",
    "h={\n",
    "  \"step\": [\n",
    "    0,234\n",
    "  ],\n",
    "  \"type\": [\n",
    "    \"string\",\"CASH_OUT\"\n",
    "  ],\n",
    "  \"amount\": [\n",
    "    0,305822.52\n",
    "  ],\n",
    "  \"nameOrig\": [\n",
    "    \"string\",\"C1376293938\"\n",
    "  ],\n",
    "  \"oldbalanceOrig\": [\n",
    "    0,0.0\n",
    "  ],\n",
    "  \"newbalanceOrig\": [\n",
    "    0,0.0\n",
    "  ],\n",
    "  \"nameDest\": [\n",
    "    \"string\",\"C182325611\"\n",
    "  ],\n",
    "  \"oldbalanceDest\": [\n",
    "    0,1569390.8999999999\n",
    "  ],\n",
    "  \"newbalanceDest\": [\n",
    "    0,1875213.4199999999\n",
    "  ]\n",
    "}\n",
    "df=pd.DataFrame.from_dict(h, orient=\"columns\").reset_index()\n",
    "prediction = model.predict(df)\n",
    "prediction_final=[\"Fraud\" if (x > 0.5) else \"Not Fraud\" for x in prediction ]\n",
    "prediction_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [10120]\n",
      "INFO:uvicorn.error:Started server process [10120]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:uvicorn.error:Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:uvicorn.error:Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:4000 (Press CTRL+C to quit)\n",
      "INFO:uvicorn.error:Uvicorn running on http://127.0.0.1:4000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:64316 - \"GET /docs HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:64316 - \"GET /openapi.json HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:64328 - \"POST /predict-fraud HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:uvicorn.error:Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:uvicorn.error:Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:uvicorn.error:Application shutdown complete.\n",
      "INFO:     Finished server process [10120]\n",
      "INFO:uvicorn.error:Finished server process [10120]\n"
     ]
    }
   ],
   "source": [
    "# First, we will need to import the library and initialize the main application object:\n",
    "import joblib\n",
    "import uvicorn\n",
    "from fastapi import FastAPI,Request\n",
    "from pydantic import BaseModel\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import nest_asyncio\n",
    "from typing import Any, Dict,List,Enum\n",
    "import numpy as np \n",
    "\n",
    "class ComplaintType(str, Enum):\n",
    "\t\tother = \"other\"\n",
    "\t\tcommercial = \"commercial\"\n",
    "\t\tpark = \"park\"\n",
    "\t\tresidential = \"residential\"\n",
    "\t\tstreet = \"street\"\n",
    "\t\tvehicle = \"vehicle\"\n",
    "\t\tworship = \"worship\"\n",
    "\t\ttruck = \"truck\"\n",
    "        \n",
    "## API INSTANTIATION\n",
    "## ----------------------------------------------------------------\n",
    "       \n",
    "app = FastAPI(\n",
    "    title=\"Fraud Detection API\",\n",
    "    description=\"A simple API that use Ml model to predict fraud \",\n",
    "    version=\"0.1\",\n",
    ")\n",
    "# Creating the data model for data validation\n",
    "class ClientData(BaseModel):\n",
    "    step: List[int]\n",
    "    type: List[str]\n",
    "    amount: List[float]\n",
    "    nameOrig:  List[str]\n",
    "    oldbalanceOrig: List[float]\n",
    "    newbalanceOrig: List[float]\n",
    "    nameDest:  List[str]\n",
    "    oldbalanceDest: List[float]\n",
    "    newbalanceDest: List[float]\n",
    "\n",
    "#load model data\n",
    "f = \"C:/Users/rzouga/Desktop/ALLINHERE/ALLINHERE/FraudDetection/COMPLETREPO/FraudDetection_Fastapi/models/lgbm_localV1.joblib\"\n",
    "model = joblib.load(f)\n",
    "# Saving the model to a serialized .pkl file\n",
    "pkl_filename = \"../model/iris_model.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(lr_model, file)\n",
    "    \n",
    "## API ENDPOINTS\n",
    "## ----------------------------------------------------------------\n",
    "\n",
    "#  Located at: http://127.0.0.1:8000/AnyNameHere\n",
    "@app.get('/{name}')\n",
    "def get_name(name: str):\n",
    "     '''\n",
    "    This is a first docstring.\n",
    "    '''\n",
    "    return {'Welcome here': f'{name}'}\n",
    "\n",
    "@app.get('/')\n",
    "def index():\n",
    "     '''\n",
    "    This is a first docstring.\n",
    "    '''\n",
    "    return {'message': 'This is a Fraud  Classification API!'}\n",
    "\n",
    "# Tester\n",
    "@app.get('/ping')\n",
    "def ping():\n",
    "     '''\n",
    "    This is a first docstring.\n",
    "    '''\n",
    "    return ('pong', 200)\n",
    "# Defining the prediction endpoint without data validation\n",
    "@api.post('/basic_predict')\n",
    "async def basic_predict(request: Request):\n",
    "     '''\n",
    "    This is a first docstring.\n",
    "    '''\n",
    "    # Getting the JSON from the body of the request\n",
    "    input_data = await request.json()\n",
    "\n",
    "     # Converting JSON to Pandas DataFrame\n",
    "    input_df = pd.DataFrame([input_data])\n",
    "\n",
    "    # Getting the prediction from the Logistic Regression model\n",
    "    pred = lr_model.predict(input_df)[0]\n",
    "\n",
    "    return pred\n",
    "# Defining the prediction endpoint without data validation\n",
    "@api.post('/basic_predict')\n",
    "async def basic_predict(request: Request):\n",
    "     '''\n",
    "    This is a first docstring.\n",
    "    '''\n",
    "\t\n",
    "\t# Getting the JSON from the body of the request\n",
    "\tinput_data = await request.json()\n",
    "\t\n",
    "\t# Converting JSON to Pandas DataFrame\n",
    "\tinput_df = pd.DataFrame([input_data])\n",
    "\t\n",
    "\t# Getting the prediction from the Logistic Regression model\n",
    "\tpred = lr_model.predict(input_df)[0]\n",
    "\t\n",
    "\treturn pred\n",
    "\t\n",
    "\n",
    "# We now define the function that will be executed for each URL request and return the value:\n",
    "@app.post(\"/predict-fraud\")\n",
    "async  def predict_fraud(item :ClientData):\n",
    "    \"\"\"\n",
    "    A simple function that receive a client data and predict Fraud.\n",
    "    :param client_data:\n",
    "    :return: prediction, probabilities\n",
    "    \n",
    "    \"\"\"\n",
    "    # perform prediction\n",
    "    #df =pd.DataFrame([item])\n",
    "    h=item.dict()\n",
    "    df=pd.DataFrame.from_dict(h, orient=\"columns\").reset_index()\n",
    "    prediction = model.predict(df)\n",
    "    prediction_final=[\"Fraud\" if (x > 0.5) else \"Not Fraud\" for x in prediction ]\n",
    "    return prediction_final\n",
    "    \n",
    "nest_asyncio.apply()\n",
    "uvicorn.run(app, port=4000)\n",
    "# uvicorn app:app --reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "iris = datasets.load_iris()\n",
    "features=pd.DataFrame(iris['data'])\n",
    "target=iris['target']\n",
    "model=LogisticRegression(max_iter=1000)\n",
    "model.fit(features,target)\n",
    " \n",
    "import pickle\n",
    "pickle.dump(model, open( \"C:/Users/rzouga/Desktop/ALLINHERE/ALLINHERE/FraudDetection/COMPLETREPO/FraudDetection_Fastapi/models/model_iris\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [7024]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:4000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:55809 - \"GET / HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:55820 - \"GET /docs HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:55823 - \"GET /openapi.json HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:55831 - \"POST /make_predictions HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:55848 - \"POST /make_predictions HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [7024]\n"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import pickle\n",
    "app = FastAPI()\n",
    " \n",
    "class iris(BaseModel):\n",
    "    a:float\n",
    "    b:float\n",
    "    c:float\n",
    "    d:float\n",
    "         \n",
    "\n",
    "#we are loading the model using pickle\n",
    "model = pickle.load(open(\"C:/Users/rzouga/Desktop/ALLINHERE/ALLINHERE/FraudDetection/COMPLETREPO/FraudDetection_Fastapi/models/model_iris\",\n",
    "                         'rb'))\n",
    " \n",
    "@app.post('/make_predictions')\n",
    "async def make_predictions(features: iris):\n",
    "    return({\"prediction\":str(model.predict([[features.a,features.b,features.c,features.d]])[0])})\n",
    "nest_asyncio.apply()\n",
    "uvicorn.run(app, port=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [7024]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:4000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:55043 - \"GET / HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:55044 - \"GET /docs HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:55044 - \"GET /openapi.json HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:55044 - \"GET /plot-iris HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [7024]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastapi import FastAPI\n",
    "from fastapi.responses import ORJSONResponse,StreamingResponse\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.get(\"/get-iris\")\n",
    "def get_iris():\n",
    "\n",
    "    import pandas as pd\n",
    "    url ='https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/0e7a9b0a5d22642a06d3d5b9bcbad9890c8ee534/iris.csv'\n",
    "    iris = pd.read_csv(url)\n",
    "    return iris\n",
    "\n",
    "@app.get(\"/plot-iris\")\n",
    "def plot_iris():\n",
    "\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    url ='https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/0e7a9b0a5d22642a06d3d5b9bcbad9890c8ee534/iris.csv'\n",
    "    iris = pd.read_csv(url)\n",
    "\n",
    "    plt.scatter(iris['sepal_length'], iris['sepal_width'])\n",
    "    plt.savefig('iris.png')\n",
    "    file = open('iris.png', mode=\"rb\")\n",
    "\n",
    "    return StreamingResponse(file, media_type=\"image/png\")\n",
    "\n",
    "nest_asyncio.apply()\n",
    "uvicorn.run(app, port=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/DeepSparkChaker/Titanic_Deep_Spark/blob/main/app.py\n",
    "https://github.com/Kunal-Varma/Deployment-of-ML-model-using-FASTAPI/tree/2cc0319abbec469010a5139f460004f2a75a7482\n",
    "    \n",
    "https://realpython.com/fastapi-python-web-apis/\n",
    "# https://github.com/tiangolo/fastapi/issues/3373\n",
    "# https://www.freecodecamp.org/news/data-science-and-machine-learning-project-house-prices/\n",
    "https://github.com/tiangolo/fastapi/issues/1616\n",
    "https://stackoverflow.com/questions/68244582/display-dataframe-as-fastapi-output\n",
    "https://www.kaggle.com/sakshigoyal7/credit-card-customers\n",
    "https://github.com/renanmouraf/data-science-house-prices    \n",
    "https://towardsdatascience.com/data-science-quick-tips-012-creating-a-machine-learning-inference-api-with-fastapi-bb6bcd0e6b01\n",
    "https://towardsdatascience.com/how-to-build-and-deploy-a-machine-learning-model-with-fastapi-64c505213857\n",
    "https://analyticsindiamag.com/complete-hands-on-guide-to-fastapi-with-machine-learning-deployment/\n",
    "https://github.com/shaz13/katana/blob/develop/Dockerfile\n",
    "best practis : \n",
    "    \n",
    "https://theaisummer.com/best-practices-deep-learning-code/    \n",
    "https://github.com/The-AI-Summer/Deep-Learning-In-Production/tree/master/2.%20Writing%20Deep%20Learning%20code:%20Best%20Practises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test \n",
    "# import requests library to make API calls\n",
    "import requests\n",
    "from predict import HousePriceModel\n",
    "\n",
    "# a sample input with all the features we \n",
    "# used to train the model\n",
    "sample_input = {'MSSubClass': 20, 'MSZoning': 'RL', \n",
    "'LotArea': 7922, 'Street': 'Pave', \n",
    "'LotShape': 'Reg', 'LandContour': 'Lvl', \n",
    "'Utilities': ': 0, 'MoSold': 1,\n",
    "'YrSold': 2010, 'SaleType': 'WD', \n",
    "'SaleCondition': 'Abnorml'}\n",
    "\n",
    "def run_prediction_from_sample():\n",
    "\n",
    "    url=\"http://127.0.0.1:8000/predict\"\n",
    "    headers = {\"Content-Type\": \"application/json\", \\\n",
    "    \"Accept\":\"text/plain\"}\n",
    "\n",
    "    response = requests.post(url, headers=headers, \\\n",
    "    json=sample_input)\n",
    "    print(\"The actual Sale Price: 109000\")\n",
    "    print(f\"The predicted Sale Price: {response.text}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_prediction_from_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doccker : \n",
    "https://github.com/dkhundley/ds-quick-tips/blob/master/012_dockerizing_fastapi/Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy + scaling :\n",
    "https://towardsdatascience.com/deploying-ml-models-in-production-with-fastapi-and-celery-7063e539a5db\n",
    "https://github.com/jonathanreadshaw/ServingMLFastCelery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda update conda\n",
    "conda install anaconda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
